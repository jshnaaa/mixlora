# MixLoRA æ–‡åŒ–æ•°æ®é›†è‡ªå®šä¹‰è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨å®šåˆ¶çš„MixLoRAè®­ç»ƒè„šæœ¬åœ¨æ–‡åŒ–æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

## ğŸ¯ ä¸»è¦ç‰¹æ€§

### âœ… å®Œå…¨æ»¡è¶³æ‚¨çš„éœ€æ±‚
- âœ… æ”¯æŒLLaMA3.1-8B-Instructæ¨¡å‹
- âœ… æ”¯æŒQwen2ç­‰å¤šç§æ¨¡å‹æ¶æ„
- âœ… æ•°æ®é›†IDå‚æ•°åŒ–é…ç½®ï¼ˆDATA_ID=2/3ï¼‰
- âœ… è‡ªåŠ¨8:1:1æ•°æ®é›†åˆ†å‰²ï¼ˆéšæœºæ‰“ä¹±ï¼‰
- âœ… ä¿å­˜è®­ç»ƒå‚æ•°æƒé‡ï¼ˆä¸ä¿å­˜å®Œæ•´æ¨¡å‹ï¼‰
- âœ… åŸºäºéªŒè¯é›†å‡†ç¡®ç‡çš„æœ€ä½³æ¨¡å‹ä¿å­˜
- âœ… è‡ªåŠ¨æµ‹è¯•é›†è¯„ä¼°
- âœ… æ™ºèƒ½ç­”æ¡ˆæå–ï¼ˆä»ç”Ÿæˆæ–‡æœ¬ä¸­æå–é˜¿æ‹‰ä¼¯æ•°å­—ï¼‰
- âœ… å®Œæ•´è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ï¼‰
- âœ… ç”Ÿæˆç­”æ¡ˆä¿å­˜ï¼ˆåŒ…å«åŸå§‹é—®é¢˜/æ­£ç¡®ç­”æ¡ˆ/é¢„æµ‹ç­”æ¡ˆ/æ˜¯å¦æ­£ç¡®ï¼‰

## ğŸ“ æ–‡ä»¶ç»“æ„

```
custom_training/
â”œâ”€â”€ train_mixlora_custom.py      # å®šåˆ¶è®­ç»ƒè„šæœ¬ï¼ˆä¸»è¦ï¼‰
â”œâ”€â”€ inference_custom.py          # å®šåˆ¶æ¨ç†è„šæœ¬
â”œâ”€â”€ run_custom_training.sh       # è®­ç»ƒå¯åŠ¨è„šæœ¬
â”œâ”€â”€ run_custom_inference.sh      # æ¨ç†å¯åŠ¨è„šæœ¬
â”œâ”€â”€ dataset.py                   # æ•°æ®é›†å¤„ç†æ¨¡å—
â””â”€â”€ CUSTOM_USAGE.md             # æœ¬è¯´æ˜æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒï¼ˆllama + culturalbenchï¼‰
./run_custom_training.sh

# è®­ç»ƒä¸åŒç»„åˆ
./run_custom_training.sh llama 2    # LLaMA + culturalbench
./run_custom_training.sh qwen 2     # Qwen + culturalbench
./run_custom_training.sh llama 3    # LLaMA + normad
./run_custom_training.sh qwen 3     # Qwen + normad
```

### 2. æ¨ç†è¯„ä¼°

```bash
# è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°è®­ç»ƒçš„æ¨¡å‹å¹¶è¯„ä¼°ï¼ˆè‡ªåŠ¨æ£€æµ‹backboneï¼‰
./run_custom_inference.sh --adapter_path auto --dataset_path /path/to/external_test.json

# è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„qwenæ¨¡å‹å¹¶è¯„ä¼°
./run_custom_inference.sh --adapter_path auto --backbone qwen --dataset_path /path/to/test.json

# æŒ‡å®šç‰¹å®šæ¨¡å‹è¿›è¡Œè¯„ä¼°
./run_custom_inference.sh --adapter_path /root/autodl-fs/data/mixlora/culturalbench_qwen_20241122_1430/best_model --dataset_path /path/to/test.json

# äº¤äº’å¼æ¨ç†ï¼ˆè‡ªåŠ¨æ£€æµ‹æœ€æ–°æ¨¡å‹ï¼‰
./run_custom_inference.sh --adapter_path auto --interactive

# äº¤äº’å¼æ¨ç†ï¼ˆæŒ‡å®šbackboneï¼‰
./run_custom_inference.sh --adapter_path auto --backbone qwen --interactive
```

## ğŸ“Š æ•°æ®é›†é…ç½®

### æ”¯æŒçš„æ•°æ®é›†
| DATA_ID | æ•°æ®é›†åç§° | è·¯å¾„ | DATASET_TAG |
|---------|------------|------|-------------|
| 2 (é»˜è®¤) | CulturalBench | `/root/autodl-fs/CulturalBench_merge_gen.json` | `culturalbench` |
| 3 | NorMaD | `/root/autodl-fs/normad_merge_gen.json` | `normad` |

### æ•°æ®æ ¼å¼è¦æ±‚
```json
{
    "instruction": "### Question: Give me the answer from 1 to 4: ...\n### Answer: ",
    "instruction_mask": "### Question: Give me the answer from 1 to 4: ...\n### Answer: ",
    "input": "",
    "output": "1",
    "label": "1"
}
```

## ğŸ”§ è®­ç»ƒé…ç½®

### æ”¯æŒçš„æ¨¡å‹æ¶æ„
| BACKBONE | æ¨¡å‹è·¯å¾„ | æ”¯æŒçŠ¶æ€ |
|----------|----------|----------|
| llama | `/root/autodl-tmp/CultureMoE/Culture_Alignment/Meta-Llama-3.1-8B-Instruct` | âœ… å®Œå…¨æ”¯æŒ |
| qwen | `/root/autodl-tmp/CultureMoE/Culture_Alignment/Meta-Qwen-2.5-7B-Instruct` | âœ… å®Œå…¨æ”¯æŒ |

### æ¨¡å‹å‚æ•°
```bash
BACKBONE="llama"       # æ¨¡å‹æ¶æ„ï¼šllama æˆ– qwen
NUM_EXPERTS=8          # MoEä¸“å®¶æ•°é‡
TOP_K=2               # è·¯ç”±é€‰æ‹©çš„ä¸“å®¶æ•°é‡
LORA_R=8              # LoRAç§©
LORA_ALPHA=16         # LoRA alphaå‚æ•°
```

### è®­ç»ƒå‚æ•°
```bash
BATCH_SIZE=4                    # æ‰¹æ¬¡å¤§å°
GRADIENT_ACCUMULATION_STEPS=4   # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
LEARNING_RATE=1e-4             # å­¦ä¹ ç‡
NUM_EPOCHS=3                   # è®­ç»ƒè½®æ•°
EVAL_INTERVAL=1                # æ¯è½®éƒ½è¿›è¡ŒéªŒè¯è¯„ä¼°
```

## ğŸ“ˆ è®­ç»ƒæµç¨‹

### è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹
1. **æ•°æ®åŠ è½½**: æ ¹æ®DATA_IDè‡ªåŠ¨åŠ è½½å¯¹åº”æ•°æ®é›†
2. **æ•°æ®åˆ†å‰²**: éšæœºæ‰“ä¹±åæŒ‰8:1:1åˆ†å‰²è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
3. **æ¨¡å‹åˆå§‹åŒ–**: åŠ è½½åŸºç¡€æ¨¡å‹å¹¶æ³¨å…¥MixLoRAé€‚é…å™¨
4. **è®­ç»ƒå¾ªç¯**:
   - æ¯ä¸ªepochååœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
   - ä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹
   - è®°å½•æ‰€æœ‰éªŒè¯ç»“æœ
5. **æœ€ç»ˆè¯„ä¼°**: ä½¿ç”¨æœ€ä½³æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
6. **ç»“æœä¿å­˜**: ä¿å­˜æ‰€æœ‰è¯„ä¼°ç»“æœå’Œç”Ÿæˆç­”æ¡ˆ

### è¾“å‡ºç›®å½•ç»“æ„
```
/root/autodl-fs/data/mixlora/${DATASET_TAG}_${BACKBONE}_YYYYMMDD_HHMM/
â”œâ”€â”€ best_model/
â”‚   â”œâ”€â”€ adapter_config.json     # é€‚é…å™¨é…ç½®
â”‚   â””â”€â”€ adapter_model.bin       # é€‚é…å™¨æƒé‡
â”œâ”€â”€ training_config.json        # è®­ç»ƒé…ç½®
â”œâ”€â”€ validation_results.json     # éªŒè¯é›†ç»“æœï¼ˆæ¯è½®ï¼‰
â”œâ”€â”€ generated_answers.json      # éªŒè¯é›†ç”Ÿæˆç­”æ¡ˆ
â””â”€â”€ test_results.json          # æµ‹è¯•é›†æœ€ç»ˆç»“æœ
```

**ç¤ºä¾‹ç›®å½•åç§°**ï¼š
- `culturalbench_llama_20241122_1430/` - LLaMAåœ¨CulturalBenchä¸Šçš„è®­ç»ƒ
- `culturalbench_qwen_20241122_1430/` - Qwenåœ¨CulturalBenchä¸Šçš„è®­ç»ƒ
- `normad_llama_20241122_1430/` - LLaMAåœ¨NorMaDä¸Šçš„è®­ç»ƒ

## ğŸ¯ è¯„ä¼°æŒ‡æ ‡

### ç”Ÿæˆç­”æ¡ˆæ ¼å¼ï¼ˆgenerated_answers.jsonï¼‰
```json
{
    "metrics": {
        "accuracy": 0.8532,
        "precision": 0.8421,
        "recall": 0.8398,
        "f1": 0.8409,
        "total_samples": 1000,
        "valid_predictions": 987
    },
    "predictions": [
        {
            "instruction": "### Question: ...",  // åŸå§‹é—®é¢˜
            "target": "2",                       // æ­£ç¡®ç­”æ¡ˆ
            "predicted": "2",                    // é¢„æµ‹ç­”æ¡ˆ
            "correct": true,                     // æ˜¯å¦æ­£ç¡®
            "generated_text": "2"               // ç”Ÿæˆçš„åŸå§‹æ–‡æœ¬
        }
    ]
}
```

### ç­”æ¡ˆæå–é€»è¾‘
ç³»ç»Ÿä¼šä»æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ä¸­æ™ºèƒ½æå–é˜¿æ‹‰ä¼¯æ•°å­—ï¼š
1. é¦–å…ˆå°è¯•å®Œå…¨åŒ¹é…
2. æŸ¥æ‰¾æ–‡æœ¬å¼€å¤´çš„é€‰æ‹©
3. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰æ•°å­—
4. é€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„é€‰æ‹©æ•°å­—
5. å¦‚æœæ²¡æ‰¾åˆ°æœ‰æ•ˆç­”æ¡ˆï¼Œæ ‡è®°ä¸ºé”™è¯¯

## ğŸ”„ æ¨ç†æ¨¡å¼

### 1. å¤–éƒ¨æ•°æ®é›†è¯„ä¼°
```bash
# è‡ªåŠ¨æ£€æµ‹backbone
./run_custom_inference.sh \
    --adapter_path /path/to/best_model \
    --dataset_path /path/to/external_test.json

# æ˜ç¡®æŒ‡å®šbackbone
./run_custom_inference.sh \
    --adapter_path /path/to/best_model \
    --backbone qwen \
    --dataset_path /path/to/external_test.json
```

### 2. äº¤äº’å¼æ¨ç†
```bash
# è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°æ¨¡å‹ï¼ˆä»»æ„backboneï¼‰
./run_custom_inference.sh --adapter_path auto --interactive

# è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„qwenæ¨¡å‹
./run_custom_inference.sh --adapter_path auto --backbone qwen --interactive
```

### 3. æ™ºèƒ½æ¨¡å‹æ£€æµ‹
- **è‡ªåŠ¨è·¯å¾„æ£€æµ‹**: ä½¿ç”¨ `--adapter_path auto` è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°è®­ç»ƒçš„æ¨¡å‹
- **æ™ºèƒ½backboneæ£€æµ‹**: ä»è·¯å¾„ä¸­è‡ªåŠ¨è¯†åˆ«æ¨¡å‹æ¶æ„ï¼ˆllama/qwenï¼‰
- **çµæ´»ç­›é€‰**: å¯ä»¥æŒ‡å®šbackboneæ¥ç­›é€‰ç‰¹å®šæ¶æ„çš„æ¨¡å‹

### 4. å¤šæ¨¡å‹ç®¡ç†
```bash
# åˆ—å‡ºæ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹
ls -la /root/autodl-fs/data/mixlora/

# ç¤ºä¾‹è¾“å‡ºï¼š
# culturalbench_llama_20241122_1430/
# culturalbench_qwen_20241122_1435/
# normad_llama_20241122_1440/
# normad_qwen_20241122_1445/

# è‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„llamaæ¨¡å‹
./run_custom_inference.sh --adapter_path auto --backbone llama --interactive

# è‡ªåŠ¨é€‰æ‹©æœ€æ–°çš„qwenæ¨¡å‹
./run_custom_inference.sh --adapter_path auto --backbone qwen --interactive
```

## ğŸ›ï¸ é«˜çº§é…ç½®

### ä¿®æ”¹è®­ç»ƒå‚æ•°
ç¼–è¾‘ `run_custom_training.sh` æ–‡ä»¶ä¸­çš„å‚æ•°ï¼š

```bash
# å¢åŠ ä¸“å®¶æ•°é‡
NUM_EXPERTS=16

# è°ƒæ•´å­¦ä¹ ç‡
LEARNING_RATE=5e-5

# æ›´é¢‘ç¹çš„è¯„ä¼°
EVAL_INTERVAL=1  # æ¯è½®è¯„ä¼°ä¸€æ¬¡

# å¢åŠ è®­ç»ƒè½®æ•°
NUM_EPOCHS=5
```

### ä¿®æ”¹æ•°æ®é›†
åœ¨ `train_mixlora_custom.py` ä¸­æ·»åŠ æ–°çš„æ•°æ®é›†é…ç½®ï¼š

```python
configs = {
    2: {
        "path": "/root/autodl-fs/CulturalBench_merge_gen.json",
        "tag": "culturalbench"
    },
    3: {
        "path": "/root/autodl-fs/normad_merge_gen.json",
        "tag": "normad"
    },
    4: {  # æ–°æ•°æ®é›†
        "path": "/path/to/new_dataset.json",
        "tag": "newdataset"
    }
}
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   BATCH_SIZE=2
   # å¢åŠ æ¢¯åº¦ç´¯ç§¯
   GRADIENT_ACCUMULATION_STEPS=8
   ```

2. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥åŸºç¡€æ¨¡å‹è·¯å¾„
   ls -la /root/autodl-tmp/CultureMoE/Culture_Alignment/Meta-Llama-3.1-8B-Instruct
   ```

3. **æ•°æ®é›†è·¯å¾„é”™è¯¯**
   ```bash
   # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
   ls -la /root/autodl-fs/CulturalBench_merge_gen.json
   ```

4. **æƒé™é—®é¢˜**
   ```bash
   chmod +x run_custom_training.sh
   chmod +x run_custom_inference.sh
   ```

### æ—¥å¿—æŸ¥çœ‹
è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯¦ç»†æ—¥å¿—ä¼šæ˜¾ç¤ºï¼š
- æ•°æ®é›†åŠ è½½ä¿¡æ¯
- æ¨¡å‹é…ç½®ä¿¡æ¯
- è®­ç»ƒè¿›åº¦
- éªŒè¯ç»“æœ
- æœ€ä½³æ¨¡å‹ä¿å­˜ä¿¡æ¯

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´è®­ç»ƒå’Œè¯„ä¼°æµç¨‹
```bash
# 1. è®­ç»ƒLLaMAæ¨¡å‹ï¼ˆculturalbenchæ•°æ®é›†ï¼‰
./run_custom_training.sh llama 2

# 2. è®­ç»ƒQwenæ¨¡å‹ï¼ˆåŒä¸€æ•°æ®é›†ï¼‰
./run_custom_training.sh qwen 2

# 3. æŸ¥çœ‹è®­ç»ƒç»“æœ
ls -la /root/autodl-fs/data/mixlora/culturalbench_*/

# 4. æ¯”è¾ƒä¸åŒæ¨¡å‹åœ¨å¤–éƒ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°
./run_custom_inference.sh --adapter_path auto --backbone llama --dataset_path /path/to/test.json --output_file llama_results.json
./run_custom_inference.sh --adapter_path auto --backbone qwen --dataset_path /path/to/test.json --output_file qwen_results.json

# 5. æŸ¥çœ‹å’Œæ¯”è¾ƒè¯„ä¼°ç»“æœ
echo "LLaMA Results:" && cat llama_results.json | grep '"accuracy"'
echo "Qwen Results:" && cat qwen_results.json | grep '"accuracy"'
```

### è®­ç»ƒnormadæ•°æ®é›†
```bash
# è®­ç»ƒLLaMAåœ¨normadæ•°æ®é›†ä¸Š
./run_custom_training.sh llama 3

# è®­ç»ƒQwenåœ¨normadæ•°æ®é›†ä¸Š
./run_custom_training.sh qwen 3

# æŸ¥çœ‹ç»“æœ
ls -la /root/autodl-fs/data/mixlora/normad_*/
```

### æ¨¡å‹æ¶æ„å¯¹æ¯”å®éªŒ
```bash
# 1. åœ¨åŒä¸€æ•°æ®é›†ä¸Šè®­ç»ƒä¸åŒæ¶æ„
./run_custom_training.sh llama 2  # LLaMA + CulturalBench
./run_custom_training.sh qwen 2   # Qwen + CulturalBench

# 2. åœ¨ä¸åŒæ•°æ®é›†ä¸Šè®­ç»ƒåŒä¸€æ¶æ„
./run_custom_training.sh llama 2  # LLaMA + CulturalBench
./run_custom_training.sh llama 3  # LLaMA + NorMaD

# 3. å…¨çŸ©é˜µå®éªŒ
./run_custom_training.sh llama 2  # LLaMA + CulturalBench
./run_custom_training.sh llama 3  # LLaMA + NorMaD
./run_custom_training.sh qwen 2   # Qwen + CulturalBench
./run_custom_training.sh qwen 3   # Qwen + NorMaD
```

è¿™å¥—å®šåˆ¶çš„è®­ç»ƒç³»ç»Ÿå®Œå…¨æ»¡è¶³æ‚¨çš„æ‰€æœ‰éœ€æ±‚ï¼Œæä¾›äº†å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œæ¨ç†æµç¨‹ï¼